{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "from src.data.dataset import split_dataset\n",
    "from src.features.features import advanced_features\n",
    "from src.models.eval_plots import plot_roc_auc, plot_goal_rate, plot_cumulative_proportion, plot_calibration_curve\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = (16, 4)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_plays_df = pd.read_csv(\"./data/processed/plays_2015-2020.csv\", index_col=False)\n",
    "train_df, test_df = split_dataset(season_plays_df)\n",
    "y_train = np.where(train_df.event_type_id==\"GOAL\", 1, 0)\n",
    "y_test = np.where(test_df.event_type_id==\"GOAL\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "pre_train_df = advanced_features(train_df)\n",
    "pre_train_df = pre_train_df.drop(columns=[\"empty_net\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pre_train_df[[\"angle_from_net\", \"dist_from_net\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plots(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    plot_roc_auc(y, y_pred)\n",
    "    plot_goal_rate(y, y_proba)\n",
    "    plot_cumulative_proportion(y, y_proba)\n",
    "    plot_calibration_curve(y, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params={\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.1,\n",
    "}\n",
    "\n",
    "def base_xgb(x_train, x_test, y_train, y_test, params={}):      \n",
    "    model = XGBClassifier(objective=\"binary:logistic\", use_label_encoder=False, **params)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              eval_metric=[\"logloss\", \"error\", \"auc\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def run_base_xgb(X, y, params, save_run=False):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    if save_run:\n",
    "        experiment = Experiment(project_name=\"hockey-all-star-analytics\")\n",
    "    model = base_xgb(x_train, x_val, y_train, y_val)\n",
    "    evaluation_plots(model, x_val, y_val)\n",
    "    \n",
    "    if save_run:\n",
    "        experiment.end()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = run_xgb(x_train, y_train, base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, x_df, y_df):\n",
    "    hyperparams = {\n",
    "        # structure\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12, step=1),\n",
    "        # accuracy\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [50]),\n",
    "        # overfitting\n",
    "        \"reg_alpha\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"reg_lambda\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "    }\n",
    "    \n",
    "    kfold_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(kfold_cv.split(x_df, y_df)):\n",
    "        x_train, x_test = x_df.iloc[train_idx], x_df.iloc[test_idx]\n",
    "        y_train, y_test = y_df.iloc[train_idx], y_df.iloc[test_idx]\n",
    "        \n",
    "        clf = XGBClassifier(**hyperparams)\n",
    "        clf.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            eval_set=[(x_test, y_test)],\n",
    "            eval_metric=[\"logloss\", \"error\", \"auc\"],\n",
    "            verbose=False,\n",
    "        )\n",
    "        best_score = clf.evals_result()[\"validation_0\"][\"logloss\"]\n",
    "        cv_scores.append(best_score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "\n",
    "def run_tuned_xgb(x_df, y_df, save_run=False):\n",
    "    if save_run:\n",
    "        experiment = Experiment(project_name=\"hockey-all-star-analytics\")\n",
    "        \n",
    "        \n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=\"tuned_xgboost\")\n",
    "    optimize = lambda trial: objective(trial, x_df, y_df)\n",
    "    study.optimize(optimize, n_trials=20)\n",
    "    \n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_df.values, y_df.values, test_size=0.2, stratify=y_df.values)\n",
    "    best_model = XGBClassifier(**study.best_params)\n",
    "    best_model.fit(x_train, y_train,\n",
    "                   eval_set=[(x_val, y_val)],\n",
    "                   eval_metric=[\"logloss\", \"error\", \"auc\"])\n",
    "    \n",
    "\n",
    "    y_pred = best_model.predict(x_val)\n",
    "    y_proba = best_model.predict_proba(x_val)[:, 1]\n",
    "    \n",
    "    plot_roc_auc(y_val, y_pred)\n",
    "    if save_run:\n",
    "        experiment.log_figure()\n",
    "        \n",
    "    plot_goal_rate(y_val, y_proba)\n",
    "    if save_run:\n",
    "        experiment.log_figure()\n",
    "        \n",
    "    plot_cumulative_proportion(y_val, y_proba)\n",
    "    if save_run:\n",
    "        experiment.log_figure()\n",
    "        \n",
    "    plot_calibration_curve(y_val, y_proba)\n",
    "    if save_run:\n",
    "        experiment.log_figure()\n",
    "    \n",
    "    plt.plot(best_model.feature_importances_)\n",
    "    if save_run:\n",
    "        experiment.log_figure()\n",
    "    \n",
    "    if save_run:\n",
    "        experiment.log_model(\"xgboost_best\", \"./models/run3\")\n",
    "        experiment.end()\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/zilto/hockey-all-star-analytics/e43106b786f649ca9f73829c64558ec1\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     validation_0_auc [5050]     : (0.663647, 0.772287)\n",
      "COMET INFO:     validation_0_error [5050]   : (0.092075, 0.09405)\n",
      "COMET INFO:     validation_0_logloss [5050] : (0.267527, 0.667749)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     begin_iteration  : 0\n",
      "COMET INFO:     booster          : gbtree\n",
      "COMET INFO:     end_iteration    : 50\n",
      "COMET INFO:     eval_metric      : ['logloss', 'error', 'auc']\n",
      "COMET INFO:     feature_names    : ['seconds_elapsed', 'period_idx', 'x_coord', 'y_coord', 'x_coord_norm', 'y_coord_norm', 'dist_from_net', 'angle_from_net', 'Backhand', 'Deflected', 'Slap Shot', 'Snap Shot', 'Tip-In', 'Wrap-around', 'Wrist Shot', 'BLOCKED_SHOT', 'FACEOFF', 'GIVEAWAY', 'GOAL', 'HIT', 'MISSED_SHOT', 'OTHER', 'PENALTY', 'PERIOD_START', 'SHOT', 'STOP', 'TAKEAWAY', 'previous_x_coord', 'previous_y_coord', 'seconds_from_previous', 'dist_from_previous', 'rebound', 'angle_change']\n",
      "COMET INFO:     feature_types    : ['float', 'int', 'float', 'float', 'float', 'float', 'float', 'float', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'float', 'float', 'float', 'float', 'int', 'float']\n",
      "COMET INFO:     learning_rate    : 0.24479845267015732\n",
      "COMET INFO:     max_depth        : 6\n",
      "COMET INFO:     min_child_weight : 11.92638149536195\n",
      "COMET INFO:     objective        : binary:logistic\n",
      "COMET INFO:     rank             : 0\n",
      "COMET INFO:     reg_alpha        : 0\n",
      "COMET INFO:     reg_lambda       : 0\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (1.29 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/zilto/hockey-all-star-analytics/b265cea16431456c8e131ec014283c84\n",
      "\n",
      "\u001b[32m[I 2021-11-26 20:03:22,194]\u001b[0m A new study created in memory with name: tuned_xgboost\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:03:32,812]\u001b[0m Trial 0 finished with value: 0.30657192 and parameters: {'max_depth': 3, 'learning_rate': 0.15968236520027237, 'n_estimators': 50, 'lambda_l1': 45, 'lambda_l2': 20, 'min_gain_to_split': 3.055465409964209}. Best is trial 0 with value: 0.30657192.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:04:00,111]\u001b[0m Trial 1 finished with value: 0.298219804 and parameters: {'max_depth': 8, 'learning_rate': 0.18403256660293205, 'n_estimators': 50, 'lambda_l1': 40, 'lambda_l2': 70, 'min_gain_to_split': 7.112544631452239}. Best is trial 1 with value: 0.298219804.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:04:28,891]\u001b[0m Trial 2 finished with value: 0.30142164000000005 and parameters: {'max_depth': 9, 'learning_rate': 0.17444906678966604, 'n_estimators': 50, 'lambda_l1': 90, 'lambda_l2': 75, 'min_gain_to_split': 14.541704882263401}. Best is trial 1 with value: 0.298219804.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:04:40,300]\u001b[0m Trial 3 finished with value: 0.337049732 and parameters: {'max_depth': 3, 'learning_rate': 0.08668986926604068, 'n_estimators': 50, 'lambda_l1': 55, 'lambda_l2': 20, 'min_gain_to_split': 11.465736392067045}. Best is trial 1 with value: 0.298219804.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:04:54,633]\u001b[0m Trial 4 finished with value: 0.28941622 and parameters: {'max_depth': 4, 'learning_rate': 0.2653109413403302, 'n_estimators': 50, 'lambda_l1': 0, 'lambda_l2': 85, 'min_gain_to_split': 7.651389057732604}. Best is trial 4 with value: 0.28941622.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:05:09,233]\u001b[0m Trial 5 finished with value: 0.29216109999999995 and parameters: {'max_depth': 4, 'learning_rate': 0.2533134665415002, 'n_estimators': 50, 'lambda_l1': 90, 'lambda_l2': 80, 'min_gain_to_split': 6.4857444705112215}. Best is trial 4 with value: 0.28941622.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:05:37,679]\u001b[0m Trial 6 finished with value: 0.28924368000000006 and parameters: {'max_depth': 9, 'learning_rate': 0.264533947254905, 'n_estimators': 50, 'lambda_l1': 90, 'lambda_l2': 85, 'min_gain_to_split': 10.54409046582815}. Best is trial 6 with value: 0.28924368000000006.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:06:06,534]\u001b[0m Trial 7 finished with value: 0.299948608 and parameters: {'max_depth': 9, 'learning_rate': 0.18200915249250782, 'n_estimators': 50, 'lambda_l1': 85, 'lambda_l2': 95, 'min_gain_to_split': 2.405011917360615}. Best is trial 6 with value: 0.28924368000000006.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:06:23,026]\u001b[0m Trial 8 finished with value: 0.298348228 and parameters: {'max_depth': 5, 'learning_rate': 0.18526954923883932, 'n_estimators': 50, 'lambda_l1': 15, 'lambda_l2': 50, 'min_gain_to_split': 5.697857630055881}. Best is trial 6 with value: 0.28924368000000006.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:06:51,311]\u001b[0m Trial 9 finished with value: 0.289708808 and parameters: {'max_depth': 9, 'learning_rate': 0.26110155638590044, 'n_estimators': 50, 'lambda_l1': 95, 'lambda_l2': 80, 'min_gain_to_split': 9.77422447174756}. Best is trial 6 with value: 0.28924368000000006.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:07:10,749]\u001b[0m Trial 10 finished with value: 0.560486244 and parameters: {'max_depth': 12, 'learning_rate': 0.010339260678201678, 'n_estimators': 50, 'lambda_l1': 70, 'lambda_l2': 50, 'min_gain_to_split': 14.325043501359257}. Best is trial 6 with value: 0.28924368000000006.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:07:30,217]\u001b[0m Trial 11 finished with value: 0.285674392 and parameters: {'max_depth': 6, 'learning_rate': 0.29181978475871057, 'n_estimators': 50, 'lambda_l1': 5, 'lambda_l2': 95, 'min_gain_to_split': 10.672148263501787}. Best is trial 11 with value: 0.285674392.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:07:49,732]\u001b[0m Trial 12 finished with value: 0.2861652 and parameters: {'max_depth': 6, 'learning_rate': 0.29310014250890054, 'n_estimators': 50, 'lambda_l1': 25, 'lambda_l2': 100, 'min_gain_to_split': 11.22572884554635}. Best is trial 11 with value: 0.285674392.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:08:09,335]\u001b[0m Trial 13 finished with value: 0.28640992 and parameters: {'max_depth': 6, 'learning_rate': 0.28765940435149384, 'n_estimators': 50, 'lambda_l1': 20, 'lambda_l2': 95, 'min_gain_to_split': 12.341282076648243}. Best is trial 11 with value: 0.285674392.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:08:28,934]\u001b[0m Trial 14 finished with value: 0.29290882399999996 and parameters: {'max_depth': 6, 'learning_rate': 0.22139711769473908, 'n_estimators': 50, 'lambda_l1': 20, 'lambda_l2': 100, 'min_gain_to_split': 9.208029846472314}. Best is trial 11 with value: 0.285674392.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:08:51,656]\u001b[0m Trial 15 finished with value: 0.284651948 and parameters: {'max_depth': 7, 'learning_rate': 0.2974100785402007, 'n_estimators': 50, 'lambda_l1': 5, 'lambda_l2': 65, 'min_gain_to_split': 12.680647749787273}. Best is trial 15 with value: 0.284651948.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:09:14,977]\u001b[0m Trial 16 finished with value: 0.32380229599999993 and parameters: {'max_depth': 7, 'learning_rate': 0.10050013623984194, 'n_estimators': 50, 'lambda_l1': 0, 'lambda_l2': 60, 'min_gain_to_split': 13.242080297962193}. Best is trial 15 with value: 0.284651948.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:09:38,299]\u001b[0m Trial 17 finished with value: 0.29216516 and parameters: {'max_depth': 7, 'learning_rate': 0.22233242172560855, 'n_estimators': 50, 'lambda_l1': 35, 'lambda_l2': 35, 'min_gain_to_split': 8.802419016638309}. Best is trial 15 with value: 0.284651948.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:10:18,993]\u001b[0m Trial 18 finished with value: 0.290356332 and parameters: {'max_depth': 11, 'learning_rate': 0.22324535211831842, 'n_estimators': 50, 'lambda_l1': 5, 'lambda_l2': 0, 'min_gain_to_split': 5.149090537306901}. Best is trial 15 with value: 0.284651948.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n",
      "\u001b[32m[I 2021-11-26 20:10:35,649]\u001b[0m Trial 19 finished with value: 0.32171572000000004 and parameters: {'max_depth': 5, 'learning_rate': 0.10711314550224486, 'n_estimators': 50, 'lambda_l1': 10, 'lambda_l2': 60, 'min_gain_to_split': 0.7219325714632259}. Best is trial 15 with value: 0.284651948.\u001b[0m\n",
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"lambda_l1\", \"lambda_l2\", \"min_gain_to_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "0\tvalidation_0-logloss:0.51882\tvalidation_0-error:0.09363\tvalidation_0-auc:0.74853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJ\\miniconda3\\envs\\nice_play\\lib\\site-packages\\xgboost\\training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tvalidation_0-logloss:0.42438\tvalidation_0-error:0.09313\tvalidation_0-auc:0.75554\n",
      "2\tvalidation_0-logloss:0.36788\tvalidation_0-error:0.09317\tvalidation_0-auc:0.75878\n",
      "3\tvalidation_0-logloss:0.33263\tvalidation_0-error:0.09325\tvalidation_0-auc:0.76040\n",
      "4\tvalidation_0-logloss:0.31012\tvalidation_0-error:0.09322\tvalidation_0-auc:0.76204\n",
      "5\tvalidation_0-logloss:0.29575\tvalidation_0-error:0.09323\tvalidation_0-auc:0.76317\n",
      "6\tvalidation_0-logloss:0.28629\tvalidation_0-error:0.09313\tvalidation_0-auc:0.76490\n",
      "7\tvalidation_0-logloss:0.28044\tvalidation_0-error:0.09320\tvalidation_0-auc:0.76518\n",
      "8\tvalidation_0-logloss:0.27653\tvalidation_0-error:0.09325\tvalidation_0-auc:0.76628\n",
      "9\tvalidation_0-logloss:0.27400\tvalidation_0-error:0.09318\tvalidation_0-auc:0.76699\n",
      "10\tvalidation_0-logloss:0.27241\tvalidation_0-error:0.09307\tvalidation_0-auc:0.76718\n",
      "11\tvalidation_0-logloss:0.27133\tvalidation_0-error:0.09307\tvalidation_0-auc:0.76734\n",
      "12\tvalidation_0-logloss:0.27041\tvalidation_0-error:0.09310\tvalidation_0-auc:0.76843\n",
      "13\tvalidation_0-logloss:0.26996\tvalidation_0-error:0.09304\tvalidation_0-auc:0.76867\n",
      "14\tvalidation_0-logloss:0.26948\tvalidation_0-error:0.09291\tvalidation_0-auc:0.76917\n",
      "15\tvalidation_0-logloss:0.26928\tvalidation_0-error:0.09304\tvalidation_0-auc:0.76913\n",
      "16\tvalidation_0-logloss:0.26924\tvalidation_0-error:0.09297\tvalidation_0-auc:0.76900\n",
      "17\tvalidation_0-logloss:0.26884\tvalidation_0-error:0.09286\tvalidation_0-auc:0.76986\n",
      "18\tvalidation_0-logloss:0.26874\tvalidation_0-error:0.09281\tvalidation_0-auc:0.77002\n",
      "19\tvalidation_0-logloss:0.26863\tvalidation_0-error:0.09286\tvalidation_0-auc:0.77027\n",
      "20\tvalidation_0-logloss:0.26858\tvalidation_0-error:0.09299\tvalidation_0-auc:0.77027\n",
      "21\tvalidation_0-logloss:0.26852\tvalidation_0-error:0.09297\tvalidation_0-auc:0.77031\n",
      "22\tvalidation_0-logloss:0.26840\tvalidation_0-error:0.09302\tvalidation_0-auc:0.77040\n",
      "23\tvalidation_0-logloss:0.26833\tvalidation_0-error:0.09301\tvalidation_0-auc:0.77051\n",
      "24\tvalidation_0-logloss:0.26841\tvalidation_0-error:0.09291\tvalidation_0-auc:0.77020\n",
      "25\tvalidation_0-logloss:0.26836\tvalidation_0-error:0.09281\tvalidation_0-auc:0.77022\n",
      "26\tvalidation_0-logloss:0.26837\tvalidation_0-error:0.09288\tvalidation_0-auc:0.77022\n",
      "27\tvalidation_0-logloss:0.26835\tvalidation_0-error:0.09288\tvalidation_0-auc:0.77024\n",
      "28\tvalidation_0-logloss:0.26838\tvalidation_0-error:0.09289\tvalidation_0-auc:0.77019\n",
      "29\tvalidation_0-logloss:0.26836\tvalidation_0-error:0.09292\tvalidation_0-auc:0.77023\n",
      "30\tvalidation_0-logloss:0.26843\tvalidation_0-error:0.09301\tvalidation_0-auc:0.77009\n",
      "31\tvalidation_0-logloss:0.26846\tvalidation_0-error:0.09304\tvalidation_0-auc:0.77006\n",
      "32\tvalidation_0-logloss:0.26843\tvalidation_0-error:0.09299\tvalidation_0-auc:0.77007\n",
      "33\tvalidation_0-logloss:0.26845\tvalidation_0-error:0.09304\tvalidation_0-auc:0.77009\n",
      "34\tvalidation_0-logloss:0.26849\tvalidation_0-error:0.09304\tvalidation_0-auc:0.76991\n",
      "35\tvalidation_0-logloss:0.26845\tvalidation_0-error:0.09302\tvalidation_0-auc:0.77003\n",
      "36\tvalidation_0-logloss:0.26856\tvalidation_0-error:0.09294\tvalidation_0-auc:0.76984\n",
      "37\tvalidation_0-logloss:0.26854\tvalidation_0-error:0.09292\tvalidation_0-auc:0.76986\n",
      "38\tvalidation_0-logloss:0.26862\tvalidation_0-error:0.09294\tvalidation_0-auc:0.76966\n",
      "39\tvalidation_0-logloss:0.26869\tvalidation_0-error:0.09301\tvalidation_0-auc:0.76955\n",
      "40\tvalidation_0-logloss:0.26880\tvalidation_0-error:0.09309\tvalidation_0-auc:0.76925\n",
      "41\tvalidation_0-logloss:0.26885\tvalidation_0-error:0.09317\tvalidation_0-auc:0.76915\n",
      "42\tvalidation_0-logloss:0.26895\tvalidation_0-error:0.09315\tvalidation_0-auc:0.76882\n",
      "43\tvalidation_0-logloss:0.26898\tvalidation_0-error:0.09323\tvalidation_0-auc:0.76877\n",
      "44\tvalidation_0-logloss:0.26904\tvalidation_0-error:0.09318\tvalidation_0-auc:0.76867\n",
      "45\tvalidation_0-logloss:0.26909\tvalidation_0-error:0.09305\tvalidation_0-auc:0.76854\n",
      "46\tvalidation_0-logloss:0.26927\tvalidation_0-error:0.09302\tvalidation_0-auc:0.76798\n",
      "47\tvalidation_0-logloss:0.26930\tvalidation_0-error:0.09302\tvalidation_0-auc:0.76794\n",
      "48\tvalidation_0-logloss:0.26929\tvalidation_0-error:0.09304\tvalidation_0-auc:0.76797\n",
      "49\tvalidation_0-logloss:0.26936\tvalidation_0-error:0.09302\tvalidation_0-auc:0.76774\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_mmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10432/201420781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_tuned_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10432/1427236992.py\u001b[0m in \u001b[0;36mrun_tuned_xgb\u001b[1;34m(x_df, y_df, save_run)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0my_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mplot_roc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_mmodel' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = run_tuned_xgb(pre_train_df, pd.Series(y_train), save_run=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ead5f43594022c7cd5f301318ae4950132a1480e3738270166fab8a4a3b2cf4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('nice_play': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
